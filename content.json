{"posts":[{"title":"从零到一的大模型之旅：一个大语言模型是如何工作的？","text":"What i cannot create, i do not understand 从2022年11月30日OpenAI发布了智能聊天对话应用ChatGPT以来，大模型在两年半的时间内几乎成为了人人尽知的词语。无论是领域前沿的研究人员，还是企业中的工程师，亦或是自媒体的从业人员，都或多或少的在主动使用大模型来提高自己的效率。凭借对知识的”压缩能力”，人们可以快速高效的获得自己想要得到的答案，人们对于知识获取的方式发生了巨大变革。 作为程序员最重要网站之一的Stack Overflow，在大模型诞生后，面临着“Stack overflow is almost dead”的趋势。 正如Richard Feynman所说：“What i cannot create, i do not understand”，了解大模型运行的基础原理总归是有益的，本文将从大模型的基础原理讲起，理清大模型“智能”背后的技术。 一、一切都是概率，预测下一个词一言以蔽之，大模型本质上是一个“单词补全器”，对于输入的一个单词序列，大模型会给出下一个可能的单词整体的概率分布。，不断的重复这个过程，大模型就能够产生出一段“有意义的”文本。如果大模型收到了下面的输入： 1I want to eat __ 他将会输出候选单词列表中每个单词作为答案的概率，比如： 123apple 0.7flower 0.2sky 0.1 大模型会选择概率最高的单词作为答案，此时用户输入的句子就会变为 1I want to eat apple. ChatGPT之所以能够根据用户的问题回答出对应的答案，本质上也是一种补全。一般情况下，基于大模型的聊天应用都会内置一个提前预制好的单词序列前缀，我们称之为System Prompt（系统提示词），这样在单次问答的场景下，大模型的输出本质上是在补全System Prompt和User System Prompt，通过这种补全机制，大模型便可以输出针对用户问题的答案。 二、向量化，确定一个单词的“语义”显然，计算机从诞生到现在只能用来处理“数字”，而我们输入的是各种自然语言，为了能够让计算机理解单词所对应的语义，我们需要建立起一座从单词到数字的桥梁，在深度学习领域中，这个桥梁叫做Embedding（向量化）。 向量化的目的是为每个单词在一个高维空间中寻找到该单词对应的向量。可以这么理解，每个单词拥有若干的特征，这些特征可以唯一的确认一个单词的含义。如果我们能可视化这个高维空间，我们可以看到意思相近的词语对应的向量挨得越近，如cat和dog，因为它们都是家养宠物。我们也可以通过单词向量之间的运算变换得到一些有意思的发现。比如： $ Vec(Germany) - Vec(Italy) + Vec(Hitler) \\approx Vec(Mussolini) $ 在GPT-3模型中，每个单词向量有12288个维度。当模型接收到一串单词序列后，便会对这个单词序列进行Embedding操作，得到大模型“实际”可以被识别的输入：一个$N * M$的矩阵，$N$为单词数目，$M$为词向量的维度。 三、如何确认上下文语境中的单词含义？Attention is All You Need！虽然向量化可以确定每个输入单词的含义，但是在不同的语境下，同样的单词却有着不同的含义，如何准确的获取每个单词在当前语境下”正确”的向量?从某种角度上讲，一旦能解决这个问题，计算机便可以“理解”句子的含义了。 2017年，Google在NIPS发表了一遍标题为《Attention Is All You Need》的论文，这篇论文通过引入了注意力机制成功的解决了在不同上下文环境下确认单词含义的挑战，这也成为了大模型技术发展的重要基石。 假设大模型输入了一段文本： 1There is a blue cat 在上述语境下，cat将不再是原本的cat，而会受到blue这个形容词的影响，那么这种“影响”是否可也被向量化呢？答案是Yes。在注意力机制中，对单词定义了一种查询操作$Query$，该操作可以理解为：“我前面有形容词吗？”或者“我前面有贬义词么”等一些语义上的讯问。 为了实现查询操作，注意力模块训练了一个矩阵$W_{q}$，将其与当前单词的向量进行点积操作即可得到当前单词的一个查询矩阵$Q$。作为$Query$的回应，注意力模块训练了另外一个矩阵$W_{k}$，前面的单词向量和$W_{k}$点积可以得到每个单词的$K$矩阵。将当前单词的$Q$和前面的每个单词的$K$进行点积，即可得到前面每个单词对当前单词的“影响力”。通过softmax方法归一化，就可以得到每个单词影响当前单词的概率。最终，为了将当前单词“校准到”真实含义的向量，注意力引入了第三个矩阵$W_{v}$，前面的每个单词和$W_{v}$矩阵进行点积后便得到了向量$V$。形式化的，注意力机制可以用如下公式计算： $Attention(Q, K, V) = softmax(\\frac{QK^{T}}{\\sqrt{d_k}})V$ 当计算完当前单词与前面每个单词的注意力后，将当前单词的的向量累加上注意力向量即可得到校准后的向量，换句话说，通过atttion模块计算后，单词的向量编码了更为丰富的含义。 上述描述的计算过程被称为“单头注意力机制”，在Google提出的论文中，Transformer架构采用了并行的多头注意力机制，也即对于每个单词并行的运行多次注意力，然后加权平均得到最终的校准后的向量。 四、Transformer！最终我们得到了大模型的基础架构：Transformer 回过头再看Transformer架构就能发现，序列首先被Embedding，然后经过多层的Attention模块不断强化单词语义，需要注意的是，Transformer在训练过程中采用了Masked Multi-Head Attention，这是为了避免在训练的过程中出现根据数据集后面的单词影响前面单词的情况，比如如果数据集是 1I want to eat _ and eggs 在预测空格部分时，应当只考虑I want to eat对空格位置的影响，所以强制将空格后续位置的Attention设置为0以避免这种影响。最终，Transformer输出下一个单词的概率分布，完成了大模型的“智能”过程。","link":"/2025/06/29/Transformer/"},{"title":"SPA第一章：静态程序分析的应用&amp;程序的不可判定性","text":"Translation of《Static Program Analysis》by Anders Møller and Michael I. Schwartzbach 静态分析是一种用来自动化回答程序中可能存在的行为的技术，在本文，我们将介绍为什么静态分析是有用的并探讨分析工具的一些基本特性。 静态程序分析的应用静态分析早在上世纪60年代就已经被用于了编译器优化，近些年来，静态分析同样可以在漏洞检查，程序验证和IDE开发环境中展现出强大的作用。接下来我们给出程序行为的一些例子以及静态分析在这些程序行为上的应用。 面向程序优化的分析如果编译器想要优化程序，那么它必须知道程序的一些性质以生成高效率的代码，例如 程序中是否包含死代码，更具体的，方法f在main方法中可达吗？如果不可达，可以降低生成编译后代码的大小。 循环中一些表达式的值是否每次都相同？如果是：这些表达式可以被提到循环外以减少重复的计算 变量x的值是否以来程序的输入？如果不依赖，x可以在编译期间就被计算出来 变量x取值的上限和下限是多少？这个答案可以用来指导编译器为x分配合适的运行时表示 p和q是否指向了内存中不相交的数据结构？这可能可以并行处理 面向程序正确性的分析大部分成功的分析工具被被设计用于检测程序中的错误，在一些如C语言这样的非安全语言中，这些异常可能会导致严重的安全风险，像Java这种更加安全的语言，异常可能会导致程序终止，例如： 是否存在一个输入导致空指针异常，除零异常或者算数溢出？ 所有的变量在其被访问前都初始化了么？ 所有的数组访问都在数组下标范围内么？ 是否存在危险的引用，如引用了已经被释放的空间地址 程序对于所有的输入是否都会中止？ 还有一些程序正确性的属性取决于程序员为程序/库定义的规范，如： 所有的断言都成功了吗 在调用hasNext之前调用next了么？ 对于某些输入，程序是否抛出了ActivityNotFoundException异常？ 针对移动应用，信息流的正确性十分重要，如 非授权用户访问文件系统的输入是否检查了？ 一些敏感信息是否可被公开访问？ 并发的使用以及事件驱动模型给出了关于程序行为的问题： 是否可能存在数据竞争？ 程序是否有可能死锁？ 面向程序开发的分析现代IDE往往集成入了大量的程序分析来帮助开发者高效的debug，重构以及理解代码，这些分析可能要回答下面的问题 第117行的方法被谁调用了？ 变量x的值是否会影响到y? x可能有哪些类型？ 近似的答案为了保证程序正确性，程序员们通常会使用大量的测试来提高程序确保会像他们想的一样执行，但是正如Dijkstra的名言： 程序测试可以展示错误的存在但是不能展示错误的不存在 我们期望了解对于所有的输入，程序有可能会出现哪些行为，并且我们期望这个过程是自动化的。一个程序分析器就是这样一个以其他程序为输入并且判决输入的程序是否具备某个特性的程序。 推理出程序的行为可能是一间极度困难的事情，哪怕是对一些小的程序，如：对于下面的程序，判断是否对于所有的整数n都会终止运行？ 123456while (n &gt; 1) { if (n % 2 == 0) // if n is even, divide it by two n = n / 2; else // if n is odd, multiply by three and add one n = 3 * n + 1;} 在1937年，Collatz推断这个答案是”yes”，截至到2020年，$n$最大已经被验证到了$2 ^ {68}$，但是没人能够证明是否对于所有的输入都能终止。 即使在逻辑上没有分支的程序也有可能很难推理，对于下面的程序，是否存在输入可以使输出为true? 123x, y, z = input()output: x * x * x + y * y * y + z * z * z == 42 这是一个1954年提出的一个open problem，直到2019年答案才被百万小时后的计算发现。 莱斯定理是1953年提出的一个通用结果，该定理表明了所有的有趣的关于程序（由图灵完备语言编写）行为的问题都是不可被判定的，在一些特殊例子下这个定理很容易被证明： 假设存在一个程序分析器可以判定程序中的变量在任意执行中是否都为常量，形式化的: 这个分析器是程序$A$，$A$以程序$T$作为输入，$T$存在一个变量$x$以及某个值$k$，判定当$T$执行时$x$的值是否总是等于$k$。 我们发现可以用这样一个分析器来解决停机问题 1234x = 17; if (TM(j)) { x = 18;} 上面的方法$TM(j)$模拟了第$j$个图灵机在输入为空时的运行，如果$A$真的存在，那么我们便可以判定停机问题，然而这是不可能的。 乍一看，我们好像得到了一个不乐观的结果，但是这个结论并不影响我们可以给出近似的答案。虽然我们无法构建出一个可以正确判定任意程序行为性质的分析器，但是我们可以构建出能给对于大多数程序提供“有用”答案的分析器。尽管理论上的完美程序分析器不存在，但是我们可以不断优化这个近似答案的精度。 近似的答案对于程序漏洞的挖掘非常有用，可以作为程序正确性的一种“弱验证”，例如，对于有指针特性的C语言，编译器不会过多的限制空指针异常的编译报错 123456789101112131415161718int main(int argc, char *argv[]) { if (argc == 42) { char *p,*q; p = NULL; printf(&quot;%s&quot;,p); } q = (char *)malloc(100); p = q; free(q); *p = ’x’; free(p); p = (char *)malloc(100); p = (char *)malloc(100); q = p; strcat(p,q); assert(argc &gt; 87);} 对于上面的程序，标准编译器gcc并不会检测到上面程序的空指针异常，要想测试到空指针异常用例必须覆盖到argc=42。然而，一旦我们有一个回答输出null的近似的答案，我们便可以在不运行程序的情况下提前检测到异常。 理想情况下，我们的近似答案是保守的（或者安全的），也即所有的错误都倾向于同一侧，这取决于我们实际场景中的需要，例如：我们想要近似估计程序的内存使用量，如果我们的估计值不低于实际的值，那么我们的估计就是保守的。保守的估计和程序分析中的Soundness原则关联密切。我们说一个程序分析器是Soundness的当这个程序分析器绝对不会给出错误的答案（但是可能会回答maybe的判断）。 再次考虑那个判定程序中变量是否为常量的问题，如果我们分析结果的目标是为了进行常量优化，那么我们的分析器应当在只有当这个变量真的是常量的时候回答yes，在判断模糊的时候回答maybe。一个方案是我们可以每次都回答maybe，因此我们面临的工程挑战是如何在展现合理的分析性能的同时尽可能的回答yes。 程序正确性的不可判定性回顾停机问题停机问题：给定一个图灵机 $M$ 和输入 $w$，判断 $M$ 在 $w$ 上是否停机。已知：停机问题是 不可判定的（图灵，1936）。 假设存在一个算法 $Correct(P)$ 能判定 任意程序 $P$ 是否正确（即 fail 状态不可达），那么我们可以用它来判定停机问题，导致矛盾。归约过程：给定一个图灵机 $M$ 和输入 $w$，构造一个新程序 $P_{M, w}$​：$P_{M, w}$​ 模拟 $M$ 在 $w$ 上的运行：如果 $M$ 在 $w$ 上停机 → ​ $P_{M, w}$ 进入 accept 状态（不违反正确性）。如果 $M$ 在 $w$ 上不停机 → $P_{M, w}$​ 永远运行（发散，不进入 fail 状态）。额外添加一个 fail 状态，并确保：仅当 $M$ 在 $w$ 上停机时，$P_{M, w}$ 可能进入 fail 状态（例如，在停机后故意进入 fail）。关键观察：如果 $M$ 在 $w$ 上不停机，则 $P_{M, w}$​ 也不会停机（不会进入 fail 状态），此时 $P_{M, w}$​ 是“正确的”（因为 fail 不可达）。如果 $M$ 在 $w$ 上 停机，则 ${P_{M, w}}$ 可以进入 fail 状态，此时 $P_{M, w}$​ 是“不正确的”。利用 $Correct(P_{M, w})$ 判断停机问题：如果 $Correct(P_{M, w})$ 返回 “True”（程序正确）→ $M$ 在 $w$ 上 不停机。如果 $Correct(P_{M, w})$ 返回 “False”（程序不正确）→ $M$ 在 $w$ 上 停机。矛盾：这样我们就用 $Correct$ 解决了停机问题，但停机问题是不可判定的，因此 $Correct$ 不可能存在。结论：程序正确性问题是不可判定的。 参考[1] https://cs.au.dk/~amoeller/spa/spa.pdf","link":"/2025/07/06/sca-01/"},{"title":"SPA第二章：一种简单的命令式编程语言","text":"Translation of《Static Program Analysis》by Anders Møller and Michael I. Schwartzbach 一种简单的命令式编程语言我们使用一种简单的命令式编程语言TIP贯穿后续的章节，该语言通过简单的语法但是足以体现出静态分析的有趣和挑战。由于静态分析的原则与语言特性息息相关，因此后续的每个章节我们会关注这个语言的不同特性。 TIP语法本节我们使用上下文无关文法来表示TIP语言的语法。TIP程序可以输入一系列整数数字然后输出一系列数字，目前为止，这门语言缺乏很多众所周知的语言特性，例如：全局变量，嵌套函数，对象以及类型。在后续的章节中我们会考虑一些其他的语言特性。 基本表达式1234567Int → 0 | 1 | -1 | 2 | -2 | . . .Id → x | y | z | . . .Exp → Int| Id| Exp + Exp | Exp - Exp | Exp * Exp | Exp / Exp | Exp &gt; Exp | Exp == Exp| ( Exp )| input 表达式Exp支持用户的输入input以及一系列整数的基本运算，对于比较运算符，如果结果为false，则值为0，否则值为1。 基本语句123456Stm → Id = Exp ;| output Exp ;| Stm Stm|| if ( Exp ) { Stm } [else { Stm }]?| while ( Exp ) { Stm } 我们使用[]?来表示这部分是可选部分。 方法一个方法包含一个方法名，一个参数列表，局部变量的定义，方法体的Statemen和一个返回表达式的return语句。 1Fun → Id ( Id , . . ., Id ) { [var Id , . . ., Id ;]? Stm return Exp; } 因此我们可以扩展出方法调用 1Exp → . . . | Id ( Exp,. . .,Exp ) 方法作为值我们还允许函数作为一等公民（first-class values）。函数名称可以像普通变量一样使用，表示对函数本身的引用。这样的函数值可以被赋值给普通变量、传递给其他函数作为参数，并从函数中返回。我们新增了一种函数调用的一般形式。 1Exp → . . .| Exp ( Exp , . . ., Exp ) 对于下面的程序，在 main 函数中，inc 函数作为参数传递给 twice 函数，而 twice 函数会调用该传入的函数两次。 123456789twice(f, x) { return f(f(x));}inc(y) { return y+1;}main(z) { return twice(inc, z);} 指针为了能够构建数据结构并动态分配内存，我们引入指针： 12345Exp → . . .| alloc Exp| &amp; Id| * Exp| null 其中，第一个表达式在堆上分配一个新的单元格，并将给定表达式的值初始化到该单元格中，最终返回指向该单元格的指针。第二个表达式创建一个指向程序变量的指针，第三个表达式则对指针值进行解引用（这一操作也被称为加载操作）。为了通过指针赋值，我们允许另一种形式的赋值操作（称为存储操作）： 1Stm → . . . | * Exp = Exp; 在这种赋值操作中，如果左侧表达式求值为一个指向单元格的指针，则右侧表达式的值会存储到该单元格中。指针与整数是两种不同的值类型，并且不允许进行指针算术运算（即不能对指针执行加减操作）。 以下示例说明了各种指针操作： 1234x = alloc null;y = &amp;x;*x = 42;z = **y; 第一行分配了一个初始值为 null 的内存单元；第二行使指针 y 指向变量 x；第三行将值 42 赋给第一行分配的内存单元（从而覆盖了原来的空值）；第四行通过两次指针解引用操作读取该内存单元的新值(因此最终z的值为42)。 Records记录是一种由多个字段组成的集合，每个字段都有一个名称和一个值。创建记录以及读取字段值的语法如下所示： 123Exp → . . .| { Id : Exp , . . ., Id : Exp }| Exp . Id 下面给出了一个例子 12x = {f: 1, g: 2};y = x.f; 第一行创建了一个包含两个字段的记录：一个字段名为 f 且值为 1，另一个字段名为 g 且值为 2。第二行读取了 f 字段的值。为了更新记录字段的值，我们允许两种其他形式的赋值操作：一种是直接写入由变量持有的记录，另一种是通过指针间接修改记录字段。 123Stm → . . .| Id . Id = Exp ;| ( * Exp ) . Id = Exp; 例如： 1234x = {f: 1, g: 2};y = &amp;x;x.f = 3;(*y).g = 4; 在这里，x 持有一个记录，y 指向同一个记录，而最后两个赋值操作更新了该记录的字段 f 和 g 的值。 记录是按值传递的，因此例如，如果 x 持有一个记录，则简单的赋值 z = x; 会将整个记录复制到 z 中。为简化处理，记录的字段值本身不能是记录（但它们可以是指针，例如指向其他记录的指针）。 程序一个TIP程序为一系列方法的集合： 1Prog → Fun . . . Fun （我们有时也会将单个函数或语句称为程序。）对于完整的程序而言，名为 main 的函数是启动执行的入口点。其参数会按顺序从输入流的开头依次传递，而它返回的值会被附加到输出流中。 TIP程序举例以下 TIP 程序均用于计算给定整数的阶乘。第一个程序是迭代实现的： 123456789iterate(n) { var f; f = 1; while (n&gt;0) { f = f*n; n = n-1; } return f;} 第二个程序是递归实现的： 123456recurse(n) { var f; if (n==0) { f=1; } else { f=n*recurse(n-1); } return f;} 第三个程序则是采用了非必要的复杂写法 123456789101112131415foo(p,x) { var f,q; if (*p==0) { f=1; } else { q = alloc 0; *q = (*p)-1; f=(*p)*(x(q,x)); } return f;}main() { var n; n = input; return foo(&amp;n,foo);} 规范化 (Normalization)在编写程序时，丰富的语法确实非常有用；但当描述和实现静态分析时，使用语法更简化的语言通常更为便捷。因此，我们有时会通过将程序转换为等价但语法更简单的形式来对其进行规范化。一种特别有用的规范化方式是展开嵌套的指针表达式，使得所有指针解引用操作都以 Id 的形式表示（而非更一般的 Exp 形式）。类似地，函数调用也始终以 Id(Id,…,Id) 的形式表示（而非 Exp(Exp,…,Exp) 的形式）。此外，对算术表达式、直接调用的参数、分支条件以及返回表达式的展开也可能具有实用价值。 例如： 1x = f(y+3)*5; 可以被规范化为： 123t1 = y+3;t2 = f(t1);x = t2*5; 对于实际编程语言，我们通常以编译器或虚拟机的中间表示（Intermediate Representation）的各种变体作为实现分析工具的基础，而非直接使用高级源代码。 抽象语法树 （Abstract Syntax Trees）抽象语法树（Abstract Syntax Trees, ASTs）作为编译器构建中的常见表示方式，为程序提供了一种适合进行流不敏感分析（flow-insensitive）的数据结构。例如，在类型检查、控制流分析以及指针分析中，ASTs 是理想的工具。这类分析忽略了函数或代码块中语句的执行顺序，而 AST 的层次化结构恰好能够直观地表示程序的静态语义，因此成为便捷的表示形式。以下是对 iterate 程序的 AST 示例说明： 通过这种表示方式，可以轻松地为程序中的每个函数提取其语句集合及其结构。 控制流图 （Control Flow Graphs）在流敏感分析中，语句顺序至关重要，因此将程序视为控制流图更为便捷。这种表示方式是程序代码的一种不同形式，其思想可以追溯到优化编译器中最早的程序分析工具。 控制流图（Control Flow Graph, CFG）是一种有向图，其中节点对应于语句，边表示可能的控制流动方向。为了方便起见，并不失一般性，我们可以假设每个 CFG 始终具有一个单一的入口点（记为 entry），以及一个单一的出口点（记为 exit）。我们可以将这些入口和出口视为无操作语句（no-op statements）。 如果 $v$ 是控制流图（CFG）中的一个节点，则 $pred(v)$ 表示所有前驱节点的集合，$succ(v)$ 表示所有后继节点的集合。 对于一个被完全规范化的程序，每个节点只对应一个操作。 目前我们仅考虑简单语句，这些语句可以通过归纳的方式构造其控制流图（CFG）。赋值、输出、返回语句和声明的 CFG 结构如下所示： 对于语句序列 S1 和 S2，我们删除 S1 的出口节点和 S2 的入口节点，并将这两个语句连接在一起。 类似地，其他控制结构也通过归纳式图构造来建模（有时会用带有 true 和 false 标签的分支边）： 通过这种系统方法，迭代阶乘函数的结果如下所示的控制流图：","link":"/2025/07/12/sca-02/"},{"title":"论文阅读：《AgentSight：System-Level Observability for AI Agents Using eBPF》","text":"Arxiv Paper: 《AgentSight: System-Level Observability for AI Agents Using eBPF》 一、概要随着大模型技术的发展，Claude Code和Gemini-cli等AI Agents的应用越来越广泛。然而，AI Agents具备的特殊性质不同于传统软件，如每次生成动态代码并执行，这给AI Agent的监控观测带来了挑战。本文提出的AgentSight是一个AgentOps的可观测框架，该框架使用boundary tracing技术，利用eBPF监控agent行为对内核指标的影响并拦截LLM的流量提取出语义企图，利用LLM对这两个流进行因果关联来实现对AI Agent行为的监控。 一、问题背景1-1. AI Agents系统AI Agents系统通常由如下核心部分组成 一个具备推理能力的LLM后端 一个工具执行框架用于LLM与系统交互 一个用来协调Prompt，工具调用与状态控制的控制循环这使得AI Agents能够规划并执行复杂的计划（例如，生成、执行一个脚本并输出数据分析报告） 1-2. AI Agents的可观测现有的方法要么只聚焦于识别调用大模型本身的意图，要么只观测Agents执行工具时产生的对系统的影响而忽略大模型的意图。 1-3. eBPF为了建立大模型意图和实际执行对系统的影响的桥梁，本文借助一个能够同时监控网络和内核活动的技术eBPF。eBPF是内核的一项基础技术，起初用于网络包的过滤，后续被扩展可以用来监控内核调用行为，被广泛应用于可观测领域。 对于AI Agents的可观测，eBPF是一项特别合适的技术，因为其既可以以极低的运行成本监控Agents与OS交互的下界（系统调用），也可以通过对TLS的解析理解LLM的意图。 二、AgentSight2-1. 要解决的问题 将Agent的意图和实际行为关联 ：不同于传统的软件系统，传统软件系统的意图都已经被明确的编码，然而AI Agent实际执行时的意图是通过自然语言传递，本质上是一种动态生成代码的过程，自然，静态分析是不可能判定Agents要做什么的。因此这就带来了一个可观测问题：监控系统如何验证系统调用满足了自然语言的意图？为了解决这个问题，就必须需要一种超越简单模式匹配的方式来理解Agents的目标。AgentSight利用了LLM来理解Agents的自然语言意图。 从噪声中分离因果信号：Agents会执行大量的操作，如执行脚本，编译，下载文件等。而操作系统默认也会有大量的系统调用，如何能够正确识别出哪些是由Agents执行的？AgentSight通过一个主动的、动态的内核 eBPF 过滤器来解决这个问题。通过跟踪进程创建事件（fork、execve），该过滤器构建了Agents活动的完整谱系树，并在内核中动态应用规则，仅将来自Agents或其后代的事件传递给用户空间。 设计原则：Boundary TracingAgentSight的设计洞察来源于所有的Agent的的所有交互都依赖于稳定操作系统边界：Agent执行工具时的内核的系统调用以及用来与LLM后端通信的网络。 AgentSight使用eBPF通过监控用户空间的SSL方法来来捕获解密后的LLM Prompts请求和相应以及内核的系统调用操作流，一个用户态的关联引擎用来将处理这两部分信息并合并为一个统一的、因果关联的trace。 三、实验验证3-1.性能平均2.9%的性能开销 3-2.案例分析 检测出Prompt注入攻击 一个软件开发Agents在clone和构建一个C项目的时候，被README文件导航到了一个网站，并通过README文件中隐藏的prompt让Agent将/etc/passwd发送到一个服务器上。AgentSight捕获到了整个的攻击链路：从最初的提取URL到最终的网络包解析，这些时间聚合为了由37个事件组成的trace，AgentSight的LLM观察者分析了该trace并给出了高置信度的攻击分数。 推理死循环检测 Agents在执行复杂任务的时候有可能因为部分工具的报错而陷入死循环。一个research agent重复使用错误的参数调用搜索工具导致一直报错陷入了死循环。AgentSight捕获到了LLM的API调用trace导致的资源消耗异常并将该trace发送给LLM观察者，LLM观察者分析出了该异常是由于持续的工具报错。 多Agents协作监控 AgentSight监控了一个由6个Agents协作配合进行软件开发的Agents队伍，捕获出了3153个事件。例如：前端Agent和测试Agent往往因为并行开发产生的文件锁导致无法处理文件，这些观测结果有助于帮助Agents的设计者更好的改进Agents的协作流程。 四、总结基于eBPF的AI Agents的可观测系统，借助eBPF对操作系统网络和内核的可观测能力以及LLM的分析能力对AI Agents的意图和行为进行关联，实验验证了其有效性和性能。","link":"/2025/08/10/AIAgentsObv/"},{"title":"SPA第三章：Lattice Theory","text":"Translation of《Static Program Analysis》by Anders Møller and Michael I. Schwartzbach 后续所介绍的静态分析技术都基于lattices的数学理论。 动机案例：符号分析作为一个动机案例，假设我们希望设计一个能够分析出程序中所有整数变量/表达式的符号（+，-，0）的静态分析算法。考虑到程序分析的不可判定性，我们的分析给出的仍然是一个近似答案，因此我们的分析算法必须考虑到无法确定的情况，为此，我们引入T作为不确定的结果，由于程序中并不只有整数类型，因此我们引入⊥作为非整数（例如，指针）。 考虑下面的程序： 12345678var a,b,c;a = 42；b = 87;if (input) { c = a + b;} else { c = a - b;} 分析应该能确定出无论对于什么样的输入a,b都是正数，而c则是不确定的，这取决于input的值。对于该分析我们有一个输出的抽象集合：{+, -, 0, ⊤, ⊥}，每个变量/表达式最终的分析结果为这个集合中的一个元素。 如上图所示，我们可以按照分析的精度从上到下将上面的五种结果排序。⊤表示所有的整数集合，⊥表示整数的空集。上图就是一个完全的格(lattice). Lattices偏序（partial order）对于集合$S$, 偏序关系⊑满足下面的三个条件： 自反性：∀x ∈ S : x ⊑ x 传递性：∀x, y, z ∈ S : x ⊑ y ∧ y ⊑ z =⇒ x ⊑ z 反对称性质：∀x, y ∈ S : x ⊑ y ∧ y ⊑ x =⇒ x = y 上述对于集合{+, -, 0, ⊤, ⊥}元素的位置排列就是满足偏序的，例如：⊥ ⊑ + ， + ⊑ ⊤。当 x ⊑ y 我们认为y是x的一个安全的近似，或者说x对于y来说是至少准确的。 上界和下界对于集合X ⊆ S，如果∀x ∈ X : x ⊑ y，则y是X的一个上界（upper bound），类似的，如果∀x ∈ X : y ⊑ x，则y是X的一个下界（lower bound）。 最小上界和最大下界X的最小上界Min_X满足：X ⊑ Min_X ∧ ∀y ∈ S : X ⊑ y =⇒ Min_X ⊑ y X的最大上界Max_X满足：Max_X ⊑ X ∧ ∀y ∈ S : y ⊑ X =⇒ y ⊑ Max_X 一个格（lattice）是一个偏序关系(S, ⊑)， 满足对于S中的任意元素x,y , x和y都存在其最小上界和最大下界。一个完全格满足对于S的每个子集X，都存在X的最小上界和最大下界。 不动点定理继续进行我们的符号分析 1234var a,b; // 1a = 42; // 2b = a + input; // 3a = a - b; // 4 我们可以推导出一个等式约束系统，让每个程序变量和行号对应一个约束变量： 12345678a1 = ⊤b1 = ⊤a2 = +b2 = b1a3 = a2b3 = a2 + ⊤a4 = a3 - b3b4 = b3 进一步的，我们可以得到下面的等式约束系统： 1234x1 = [a -&gt; ⊤, b -&gt; ⊤]x2 = x1[a -&gt; +]x3 = x2[b -&gt; x2(a) + ⊤]x4 = x3[a -&gt; x3(a) - x3(b)] 我们定义方法：f : L1 → L2，且f是格单调的当f满足：∀x, y ∈ L1 : x ⊑ y =⇒ f(x) ⊑ f(y)。 令L是一个完全格，我们定义x ∈ L是一个不动点如果f(x) = x, 定义x是一个最小不动点当f的每个不动点y满足：x ⊑ y 。 我们构造下面的等式系统 1234f1(x1, . . . , x4) = [a → ⊤, b → ⊤]f2(x1, . . . , x4) = x1[a → +]f3(x1, . . . , x4) = x2[b → x2(a) + ⊤]f4(x1, . . . , x4) = x3[a → x3(a) - x3(b)] 将上述方法聚合可得到：f(x1, . . . , xn) = f(f1(x1, . . . , xn), . . . , fn(x1, . . . , xn))即x = f(x) 不动点定理在一个完全格L中，每个单调函数f: L -&gt; L有一个唯一的不动点lpf(f): 该定理告诉我们一个重要的结论：静态分析中唯一的接近精准的答案永远存在并且可以在有限的步骤内求解出来。 参考[1] https://cs.au.dk/~amoeller/spa/spa.pdf","link":"/2025/08/24/sca-03-lattice/"},{"title":"论文阅读：《The Hidden Cost of Readability： How Code Formatting SilentlyConsumes Your LLM Budget》","text":"Arxiv Paper(ICSE’26): 《The Hidden Cost of Readability: How Code Formatting SilentlyConsumes Your LLM Budget》 一、摘要一句话概述：文章验证了大模型在处理代码生成任务时(FIM)，代码是否进行格式化（换行，空格，缩进…）并不影响大模型对任务的处理效果。 二、研究问题 RQ1：在处理非格式化代码时，LLMs是否还能够保持处理格式化代码时的表现？代码的格式化是如何影响LLMs的效率的？ RQ2：每一种独立的格式化元素对模型效率和表现的影响如何？ RQ3：如何最小化LLMs的token开销 三、实验1. 任务和数据集文章采用了Fill-in-the-Middle代码补全任务来验证，数据集采用McEval的子集，只针对Java，Python，C++和C#四种生产常用的编程语言。 2. 大模型 支持OpenAPI的大模型：GPT-3.5-turbo, GPT-4o-mini, GPT-4o, Gemini-1.5, Claude-3.7 开源权重的大模型：Phi-3.5， Qwen-2.5， MagiCoder， DeepSeek-V3， Deepseek-coder-1.3B 3. 评估指标 Pass@1：生成的代码一次性通过单测的概率 输入和输出的Token数目 四. 实验结果 结论：移除掉不影响语义的代码格式化符号可以显著的降低模型的token输入数目（除了Python这种本身依赖格式化来保证语义的语言），输入token平均降低了**24.6%**，并且大模型在处理非格式化的代码时效果并未受到影响。 结论：和移除掉所有的格式化符号不同，移除掉单个的格式化符号对于某些LLM可能带来一定的负作用（如Gemini-1.5），而Claude-3.7和GPT-4则表现出了较强的鲁棒性。 五、如何减少生成的Token？即使输入的token是非格式化的，但是LLMs仍然倾向于生成格式化的代码作为输出，为了减少生成的Token有以下两个方案 1. 提示大模型生成非格式化的代码 结论：提示大模型生成非格式化的代码显著降低了output token的数目，但是要注意prompt长度带来的开销。 2. 微调大模型 6. 结论文章揭示了在大语言模型（LLM）处理过程中，代码可读性的隐性成本：格式化元素大约消耗了24.5%的token，而对于LLM效果上的提升却十分有限。文章分析识别了三种格式化元素的贡献：空格、缩进和换行，并展示了通过在未格式化的代码上进行微调和提示，可以进一步减少token使用，同时不影响LLM输出的质量，降本好文。","link":"/2025/09/21/The_Hidden_Cost_of_Readability/"},{"title":"Two Approaches to Fast Bytecode Frontend for Static Analysis","text":"Tai-e的新前端实现，发表于OOPSLA 2025 之前在公司项目里使用了Tai-e用来分析Java程序的Call Graph，但是之前Tai-e的前端依赖Soot将字节码转换为IR然后进行分析。本文介绍了Tai-e自己重新实现的新前端，摆脱了对Soot的依赖，并且性能有了大幅提升。 一、背景1-1. 为什么针对Java的静态分析需要以字节码作为输入？对于Java静态分析工具，相对于分析源代码，分析字节码有以下优势： 字节码是目标代码，Java程序要想执行都必须先编译成为字节码 相对于快速迭代的Java源代码语法特性，字节码的特性更加稳定不易变，可以大幅降低对于静态分析工具的维护成本 可以同时对Java程序所依赖的库进行分析，而源代码分析做不到 也支持分析其他的基于JVM的语言，如SCALA和Kotlin 1-2. 分析字节码为什么需要将字节码转换为3地址码（3-address code） 上图给出了一个简单的Java程序以及对应的字节码和转换后的三地址码，对于a = a + 1这条语句，字节码由四条指令完成 1234iload #1iconst 1iaddistore #1 而对于三地址码则是 1a = a + 1 这就意味着在数据流分析中如果直接对字节码分析需要记录更多的指令信息，由于Java字节码是基于栈的指令集，对于源代码直观的运算/表达式在栈中可能是非常复杂的操作序列，这对数据流分析是不利的，这也是为什么Java静态分析工具需要将字节码翻译成为对于静态分析算法更加直观的三地址码。 1-3. 将字节码翻译成3-ac的挑战将字节码翻译成3-ac主要面临两个挑战 如何将复杂的栈运算翻译成为对应的3-ac的运算 字节码中存在重复定义的slot，字节码经常复用同一个slot作为不同的变量，比如例子中的slot #2既是do while基本快中的变量b，也是外面的变量b，如果静态分析算法不能理清楚slot的对应的变量关系而是将其作为一个变量就会大幅降低静态分析算法的精度（尤其是依赖语句执行顺寻的流敏感算法）。 二、3AC生成方法（优化一）2-1. 动机将字节码翻译成为3-ac的关键在于理清楚字节码中的Def-Use关系，也即一个变量被定义后在哪里被使用了,本文的方法发现在字节码中的def-use可以分为两类 Stack Def-Use：当字节码中的指令i1通过堆栈操作产生一个值（def）然后被指令i2使用（use） Local Def-Use：当字节码中的指令i1通过store命令将值存放到slot中（def）然后被指令i2通过load命令从该slot中读取（use） 上述两类的Def-Use有各自的特点： Stack Def-Use往往是def &lt; use的（定义变量的位置在使用变量位置的前面）且一般不会跨基本块 Local Def-Use往往是use &lt; def的（使用变量的位置在定义变量位置的前面）且往往是跨基本块的（比如例子中给出的第六行的字节码istore #1和第三行的iload #1） 考虑上述两种Def-Use关系的特点，这两种可以分开各自处理。 2-2. Soot &amp; Wala的不足 Soot通过分析全局的def-use关系来构建ssa形式的3-ac，为了解决重复slot定义的问题，soot单独设置了一个split paas来分离共享同一个slot的变量 然而这个问题只存在于Local Def-Use中，无需考虑Stack Def-Use，因此Soot对于全局指令的分析带来了不必要的开销。 Wala通过抽象解释（abstract interpretation）来生成3-ac，也即将栈的操作抽象成为对于的状态转换函数，然后迭代直到到达分析的不动点，还是以上述例子来说明WALA的工作流程：WALA先遍历1-11行的指令，到达第11行之后需要继续访问11行指令的其中一个后继指令，如果继续访问第3行的指令，那么3-11行的所有指令必须全部被重复访问计算，这种重复的访问会带来潜在的性能开销。 2-3. 模式感知的三地址码生成本文将字节码翻译到3ac的过程拆分成为两个步骤 BC-SSA：通过分析Local Def-Use，将字节码“预处理”成为SSA形式，也即对于每次的store操作建立对应的不同版本的变量，然后通过插入Phi函数来表示有多个版本情况时候的变量定义，这一部分并未在文章中详细介绍，使用了《A Simple, Fast Dominance Algorithm》计算CFG中计算支配关系的算法用来处理Phi函数。 BC-3AC：将BC-SSA输出的字节码生成为三地址码，这里是通过抽象解释完成的，论文对这部分做了重点介绍。 2-3-1. 基于抽象解释的三地址码生成抽象解释的核心逻辑是在不运行程序的情况下对程序的状态进行建模，然后设计出针对每条字节码指令执行时所带来的状态转换，下面给出了抽象解释算法的符号定义。 全局的State由JVM栈状态和Slot变量构成，分别是一个列表和一个映射集合，对于每条指令都会根据指令的语义进行对应的状态转换从而生成新的状态，GEN则是根据指令以及当前的状态生成对应的3ac，下面是文章中给出的几个指令转换以及生成3ac的例子。 对于CFG来说，不同的执行路径会产生不同的状态，当处理完某个CFG Node所有前驱节点的状态后，需要对这些状态进行JOIN操作，论文定义了两种JOIN操作分别对栈和Slot进行Join。 2-3-2. 一次pass完成抽象解释WALA在进行抽象解释的时候需要不断迭代状态转移直到所有状态不再改变（也即到达不动点），本文的方案仅需要对CFG的每个节点遍历一次即可完成抽象解释。由于之前已经生成了SSA，所以对于Local变量不会被重复定义，避免了重复迭代的情况。 而对于栈状态的迭代只需要避免重复遍历循环头节点即可，一个循环头节点存在多个前驱节点（一个来自循环外，一个或多个是循环内跳转回边） 。对于这种循环头的节点，文章的做法是不等待迭代，直接为输入栈的每个位置生成一个新的变量，假设栈的高度是h，则他就会创建一个新的栈 [Vh, Vh-1, …, V1]并为每个变量生成Phi函数，这其实是一种保守的假设。但是文章指出在实践中大多数循环头的入口栈大多数都是空的，所以这个方案在理论上虽然不够精确但是在大多数情况下十分高效。 2-3-3. 冗余代码消除由于抽象解释通常会引入中间变量来保存值，因此难免会出现冗余的代码和变量定义，论文考虑了两种可以优化的case。 Single-Def vars：v := t中的v只被定义了一次（这种case会出现在Non-SSA中） Single-Use vars：v:=t中的t只被使用了一次，则可以将v:=t优化为v:=e。论文采用的方案是通过INVALID来检查是否可以内联，如果不可以则FALLBACK回正常生成中。 2-3-4. 完整算法 三、基于剪枝的类型推导（优化二）生成完成3AC后需要对每个变量的类型进行推导，类型推导本质上是一个约束求解问题，下面给出了一个例子 传统的方法是首先生成所有的def valid的类型集合，然后根据use valid去过滤。论文则是根据use的情况不去生成无用的候选类型，可以提前使用use constraints。核心算法如下：基本逻辑是根据use-constraints前向传播，在计算的define-constraints的时候剪枝。 四、实验结果4-1. 速度Soot：14.2X，WALA：14.5X，SootUp：75.2X 4-2. 字节码语义保留的正确性论文通过往返测试来确保生成的IR保留了字节码的语义，也即将IR重新转为字节码，通过比较前后两种字节码的测试情况来验证方法的正确性 五、总结论文通过将def-use分而治之对生成3ac的过程进行优化，先生成ssa保证后续的抽象解释只需要单次遍历即可完成，避免了循环迭代到不动点的额外开销。针对类型推导，通过提前使用use-constraints过滤无效的use-constraints计算，达到了卓越的提升效果。","link":"/2025/11/01/Tai-e-new-front/"}],"tags":[],"categories":[],"pages":[]}